{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression and Lasso Regression\n",
    "\n",
    "También son llamados métodos de regularización. Se utilizan especialmente cuando el número de variables predictoras es mayor al número de observaciones. Con ellos:\n",
    "\n",
    "   1. Se logra que los coeficientes del modelo tiendan a cero.\n",
    "   2. Se minimiza el riesgo de _overfitting_.\n",
    "   3. Se reduce la varianza.\n",
    "   4. Se atenúa el efecto de la correlación entre las variables predictoras.\n",
    "   5. Se reduce la influencia en el modelo de las variables predictoras menos relevantes.\n",
    "\n",
    "**Ridge Regression:**\n",
    "\n",
    "- Se agrega una penalización equivalente al cuadrado de la magnitud de los coeficientes.\n",
    "\n",
    "- Se minimiza: $\\displaystyle \\sum_{i = 1}^{n} (y_{i} - \\hat{y}_{i})^{2} + \\lambda \\sum_{j = 1}^{p} \\beta_{j}^{2}$, donde\n",
    "\n",
    "$\\displaystyle \\sum_{i = 1}^{n} (y_{i} - \\hat{y}_{i})^{2} = $ Suma del cuadrado de los residuales.\n",
    "\n",
    "$\\displaystyle \\sum_{j = 1}^{p} \\beta_{j}^{2} = $ Se penaliza la suma de los coeficientes elevados al cuadrado.\n",
    "\n",
    "$\\lambda = $ Determina el peso de la penalización.\n",
    "\n",
    "\n",
    "_Notas:_\n",
    "\n",
    "- Si $\\lambda = 0$ entonces se tiene el modelo de regresión lineal simple.\n",
    "\n",
    "- Si $\\lambda \\to \\infty$ entonces la pendiente de la recta de los valores estimados tiende a cero. Las predicciones se hacen cada vez menos sensibles a las variables explicativas.\n",
    "\n",
    "- Se utiliza la validación cruzada (_Cross Validation_) para encontrar $\\lambda$ que cumpla $0 < \\lambda < \\infty$. Con esto se determina cuál valor tiene la menor varianza.\n",
    "\n",
    "**Lasso Regression _(Least Absolute Shrinkage and Selection Operator)_:**\n",
    "\n",
    "- Se agrega una penalización equivalente al valor absoluto de la magnitud de los coeficientes.\n",
    "\n",
    "- Se minimiza: $\\displaystyle \\sum_{i = 1}^{n} (y_{i} - \\hat{y}_{i})^{2} + \\lambda \\sum_{j = 1}^{p} |\\beta_{j}|$\n",
    "\n",
    "_Nota:_\n",
    "- Si $\\lambda \\to \\infty$ entonces la pendiente de la recta de los valores estimados es cero. Los pesos $\\beta_{j}$ de las variables que no explican el modelo se hacen cero. Esto hace que la ecuación a minimizar sea más sencilla y más fácil de interpertar cuando se tienen muchas variables que no se utilizan.\n",
    "\n",
    "\n",
    "**Interpretación de los coeficientes:**\n",
    "\n",
    "Cada valor $\\beta_{i}$ corresponde a una variable predictora. El valor indica qué tanto cambia **Y** por cada unidad que cambia **$X_{i}$** mientras las demás **$X_{j}$** (con $i \\neq j$) permanecen constantes.\n",
    "\n",
    "Entre más grande sea el valor de $\\beta_{i}$, más significativa es la _i-ésima_ variable predictora ($X_{i}$). La influencia puede ser positiva o negativa.\n",
    "\n",
    "Las variables con $\\beta_{i} > 0$ y grandes, tienen mayor influencia en el modelo que variables con $\\beta_{i}$ cercanos a cero.\n",
    "\n",
    "Las variables con $\\beta_{i} < 0$ tienen un efecto negativo en las predicciones del modelo.\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "En este archivo se verán 2 ejemplos que muestran ambas regresiones.\n",
    "\n",
    "   - En _Ridge Regression_ se van a comparar 3 modelos\n",
    "        1. $\\lambda = 5$\n",
    "\n",
    "        2. $\\lambda = 0$\n",
    "\n",
    "        3. $\\lambda$ elegida con _cross validation_\n",
    "\n",
    "   Para elegir el mejor de los 3 modelos vamos a calcular el error cuadrático medio: $ECM_{\\lambda} = \\dfrac{\\displaystyle \\sum_{i = 1}^{n} (real_{i} − estimado_{i})^{2}}{n}$.\n",
    "\n",
    "   Se elegirá el que tenga el menor $ECM_{\\lambda}$\n",
    "   \n",
    "   - En _LASSO Regression_ se va a definir el modelo utilizando $\\lambda$ elegida con _cross validation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan las librerías que se van a utilizar en ambos ejemplos\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 25) # by default is 10, if change to None print ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) EXTRAER DATOS\n",
    "# Los datos pueden encontrarse en diferentes formatos, en nuestro caso están en formato csv.\n",
    "\n",
    "# Se carga la base de datos\n",
    "df = pd.read_csv('Hitters.csv') #Se encuentra en la misma carpeta que el jupyter notebook\n",
    "print(df.shape) #Se tienen 322 renglones y 21 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 2) ANÁLISIS EXPLORATORIO\n",
    "# Se realiza una descripción analítica de los datos.\n",
    "df.head()# Se muestran los primeros 5 datos del data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos corresponden a la información de 322 jugadores de baseball en 1986 y 1987.\n",
    "\n",
    "Los términos utilizados se pueden encontrar en: https://www.mlb.com/glossary/\n",
    "\n",
    "La información que se tiene de cada uno de los jugadores es (21 columnas):\n",
    "\n",
    "   - **Player:** Nombre del jugador\n",
    "   - **AtBat:** Número de veces al bat en 1986\n",
    "   - **Hits:**  Número de hits en 1986 (cuando se le pega a la pelota y se llega al menos a la primera base)\n",
    "   - **HmRun:** Número de home runs en 1986\n",
    "   - **Runs:** Número de carreras en 1986\n",
    "   - **RBI:** Número de carreras impulsadas (carreras hechas por sus compañeros a causa suya) en 1986, (Runs Batted In)\n",
    "   - **Walks:** Número de bases por bolas en 1986\n",
    "\n",
    "   - **Years:** Número de años en ligas mayores\n",
    "   - **CAtBat:** Número de veces al bat durante su carrera\n",
    "   - **CHits:** Número de hits durante su carrera\n",
    "   - **CHmRun:** Número de home runs durante su carrera\n",
    "   - **CRuns:** Número de carreras durante su carrera\n",
    "   - **CRBI:** Número de carreras impulsadas durante su carrera\n",
    "   - **CWalks:** Número de bases por bolas durante su carrera\n",
    "\n",
    "   - **League:** Variable categórica que indica la liga del jugador al final de 1986 (A = American League -> Bateador designado batea en lugar del pitcher, N = National League -> Todos los jugadores batean)\n",
    "   - **Division:** Variable categórica que indica la división del jugador al final de 1986 (E = East, W = West)\n",
    "   - **PutOuts:** Número de outs en 1986\n",
    "   - **Assists:** Número de asistencias en 1986 (se acredita a un jugador defensivo que lanza o toca la pelota antes de un out)\n",
    "   - **Errors:** Número de errores en 1986\n",
    "\n",
    "   - **Salary:** Salario anual de 1987 en miles de dólares al día inaugural\n",
    "   - **NewLeague:** Factor con niveles A y N que indican la liga del jugador al inicio de 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cuenta el número de NaN's por columna\n",
    "df.isnull().sum() #Se tienen 59 NaN's en la columna del Salario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#En este caso vamos a eliminar los renglones de los jugadores con NaN en su salario.\n",
    "#También vamos a eliminar la columna del nombre del jugador.\n",
    "df = pd.read_csv('Hitters.csv').dropna().drop('Player', axis = 1)\n",
    "print('Antes se tenían 322 renglones y 21 columnas.\\nAhora se tienen ',df.shape[0],' renglones y ',df.shape[1],' columnas.')\n",
    "print('Se eliminaron ',322-df.shape[0],' renglones.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen las varibles X (predictoras) y Y (dependiente)\n",
    "Y = df.Salary\n",
    "X = df.drop(['Salary'], axis = 1)#Se elimina la columna del salario\n",
    "print(type(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las variables dummies para las variables categóricas\n",
    "dummies = pd.get_dummies(X[['League', 'Division', 'NewLeague']])\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan las columnas 'League', 'Division', 'NewLeague' y se reemplazan por\n",
    "#las variables dummies (una por cada columna).\n",
    "#Recordemos los valores de cada variable:\n",
    "# 'League' y 'NewLeague': A y N\n",
    "# 'Division': E y W\n",
    "\n",
    "X = X.drop(['League', 'Division', 'NewLeague'], axis = 1).astype('float64')\n",
    "X = pd.concat([X, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis = 1)\n",
    "\n",
    "print(X.shape[0],' renglones\\n',X.shape[1],' columnas')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cuenta el número de NaN's por columna\n",
    "df.isnull().sum() #No hay NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define un vector con las descripciones de cada columna en el data frame X:\n",
    "descrip = ['Número de veces al bat en 1986',\n",
    "           'Número de hits en 1986',\n",
    "           'Número de home runs en 1986',\n",
    "           'Número de carreras en 1986',\n",
    "           'Número de carreras impulsadas en 1986',\n",
    "           'Número de bases por bolas en 1986',\n",
    "           'Número de años en ligas mayores',\n",
    "           'Número de veces al bat durante su carrera',\n",
    "           'Número de hits durante su carrera',\n",
    "           'Número de home runs durante su carrera',\n",
    "           'Número de carreras durante su carrera',\n",
    "           'Número de carreras impulsadas durante su carrera',\n",
    "           'Número de bases por bolas durante su carrera',\n",
    "           'Número de outs en 1986',\n",
    "           'Número de asistencias en 1986',\n",
    "           'Número de errores en 1986',\n",
    "           'Liga del jugador al final de 1986: 0 = American League, 1 = National League',\n",
    "           'División del jugador al final de 1986: 0 = East, 1 = West',\n",
    "           'Liga del jugador al inicio de 1987: 0 = American League, 1 = National League']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) VISUALIZACIÓN DE LOS DATOS\n",
    "# Para entender mejor los datos es necesario graficarlos.\n",
    "\n",
    "#Histograma de la frecuencia relativa del salario con la densidad ajustada correspondiente.\n",
    "sns.distplot(Y)\n",
    "plt.title('Histograma de la frecuencia relativa del salario')\n",
    "plt.xlabel('Salario')\n",
    "plt.ylabel('Frecuencia relativa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogramas de cada columna\n",
    "for i in range(0,X.shape[1]): #[0,19)\n",
    "    print('Mínimo = ',min(X.iloc[:,i]))\n",
    "    print('Máximo = ',max(X.iloc[:,i]))\n",
    "    plt.hist(X.iloc[:,i])\n",
    "    plt.title('Histograma de la columna ' + X.columns[i])\n",
    "    plt.xlabel(descrip[i])\n",
    "    plt.ylabel('Número de jugadores')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplots de cada columna\n",
    "for i in range(0,(X.shape[1]-3)): #[0,16)\n",
    "    print('Promedio = ',round(np.mean(X.iloc[:,i]),2))\n",
    "    plt.title('Boxplot de la columna ' + X.columns[i])\n",
    "    sns.boxplot(x=X.columns[i], data=X).set(xlabel=descrip[i])\n",
    "    plt.show()\n",
    "#No se muestran las gráficas de las columnas con variables dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Se muestra la correlación entre las variables\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se muestra la correlación entre el salario y las variables predictivas\n",
    "for i in [0,4,8,12]:\n",
    "    sns.pairplot(data=df,\n",
    "                  y_vars=['Salary'],\n",
    "                  x_vars=['Salary',X.columns[i], X.columns[i+1], X.columns[i+2],X.columns[i+3]])\n",
    "    plt.show()\n",
    "#No se muestran las gráficas de las columnas con variables dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el vector de lambdas, recordemos que el string 'lambda' está reservado para \n",
    "#las funciones con una sola instrucción.\n",
    "#El vector tiene un gran rango de valores para poder cubrir varios escenarios.\n",
    "\n",
    "print(np.linspace(10,-2,100)[:10])\n",
    "\n",
    "lambdas = 10**np.linspace(10,-2,100)*0.5\n",
    "'''\n",
    "Con np.linspace(10,-2,100) se define un vector que va de 10 a -2, tiene 100 entradas .\n",
    "Se eleva 10 a cada uno de esos valores.\n",
    "Finalmente, cada una de esas entradas se multiplica por 0.5.\n",
    "'''\n",
    "print(lambdas[:10]) #Se muestran los primeros 10 valores del vector\n",
    "print(lambdas[-10:]) #Se muestran los últimos 10 valores del vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) DIVIDIR LOS DATOS\n",
    "# Se separan los datos en 2 grupos (usualmente 80% y 20%):\n",
    "# i) Para entrenar al modelo (80%)\n",
    "# ii) Para probar el modelo (20%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, #Se indican los vectores que se van a dividir\n",
    "                                                    test_size = 0.2, #Se indica el porcentaje de los datos para probar el modelo\n",
    "                                                    random_state = 1) #Se fija la semilla\n",
    "\n",
    "# Nota: Tomar la muestra aleatoria es muy importante porque en caso de que los datos estén\n",
    "#ordenados el algoritmo no aprende adecuadamente. Por ejemplo si tenemos 80 sanos y 20 enfermos,\n",
    "#sólo se tomarían los 80 sanos (por ser los primeros 80)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan las librerías que se van a utilizar\n",
    "from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las variables que se van a utilizar\n",
    "ridge = Ridge(normalize = True)#Para estandarizar las variables el parámetro \"normalize\" es verdadero\n",
    "coefs = []\n",
    "\n",
    "#Se llena la matriz con coeficientes asociadas a cada variable independiente y a cada valor de lambda\n",
    "for k in lambdas:\n",
    "    ridge.set_params(alpha = k)#Se toman los valores de lambda\n",
    "    ridge.fit(X_train, Y_train)#Se ajusta el modelo\n",
    "    coefs.append(ridge.coef_)#Se generan los coeficientes correspondientes\n",
    "    \n",
    "print(np.shape(coefs))\n",
    "coefs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperamos que los coeficientes estimados sean cada vez más pequeños mientras lambda se hace mas grande.\n",
    "\n",
    "Se espera que los coeficientes estimados sean más grandes si lambda es pequeña.\n",
    "\n",
    "Si $\\lambda \\to \\infty \\,\\, \\Rightarrow \\beta \\to 0$ porque se quiere minimizar la función correspondiente.\n",
    "\n",
    "Entre menos pronunciada esté una pendiente implica que a cambios pequeños en **X**, se tienen cambios pequeños en **Y**.\n",
    "\n",
    "Al contrario si se tiene una pendiente pronunciada, entonces a cambios pequeños en **X**, se tienen cambios grandes en **Y**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafiquemos\n",
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('beta')\n",
    "\n",
    "#En esta gráfica vemos que entre más grande es lambda, más cercano a cero es beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\lambda = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) CONSTRUIR UN MODELO\n",
    "mod_ridge5 = Ridge(alpha = 5, normalize = True)\n",
    "mod_ridge5.fit(X_train, Y_train)\n",
    "print(pd.Series(mod_ridge5.coef_, index = X.columns)) # Valor de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los valores de los coeficientes (betas).\n",
    "eje_X = range(1,len(mod_ridge5.coef_)+1,1)\n",
    "plt.scatter(eje_X, mod_ridge5.coef_, color = 'purple')\n",
    "plt.title('Betas')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Valor de coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de los coeficientes\n",
    "\n",
    "Con la gráfica anterior podemos ver que la mayoría de los coeficientes están cercanos a cero.\n",
    "\n",
    "Esto nos indica que la mayoría de las variables no tienen una gran influencia en el modelo.\n",
    "\n",
    "Las variables con $\\beta_{i} > 1$ son:\n",
    "\n",
    "|    Variable   | $\\beta$ |\n",
    "|:-----------:|:-------:|\n",
    "|    HmRun    |  1.40  |\n",
    "|    Years    |  2.32  |\n",
    "|   League_N  |  3.17  |\n",
    "| NewLeague_N |  4.09  |\n",
    "\n",
    "\n",
    "Estas variables son las que más impactan en el sueldo del jugador.\n",
    "\n",
    "El coeficiente de la variable _Division_W_ es $-24.628$. Esta variable impacta de manera negativa en el modelo.\n",
    "\n",
    "Podemos concluir que jugar en la división del oeste implica tener un menor sueldo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) PREDICCIONES\n",
    "# Se hacen las predicciones con \"X_test\"\n",
    "Y_pred = mod_ridge5.predict(X_test)\n",
    "#print(X_test) #data frame\n",
    "#print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados de la predicción.\n",
    "plt.scatter(Y_test, Y_pred, color = 'blue')\n",
    "plt.title('Predicciones')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Salario estimado')\n",
    "plt.show()\n",
    "\n",
    "# Nota: No estamos graficando contra ninguna variable explicativa.\n",
    "#Los valores de las predicciones se graficaron contra el salario real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) EVALUACIÓN DEL MODELO CON lambda = 5\n",
    "#Calculamos el error cuadrático medio: $\\dfrac{\\displaystyle \\sum_{i = 1}^{n} (real_{i} − estimado_{i})^{2}}{n}$\n",
    "ECM5 = round(mean_squared_error(Y_test, Y_pred),3) \n",
    "print(ECM5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\lambda = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) CONSTRUIR UN MODELO\n",
    "mod_ridge0 = Ridge(alpha = 0, normalize = True)\n",
    "mod_ridge0.fit(X_train, Y_train)\n",
    "print(pd.Series(mod_ridge0.coef_, index = X.columns)) # Valor de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los valores de los coeficientes (betas).\n",
    "eje_X = range(1,len(mod_ridge0.coef_)+1,1)\n",
    "plt.scatter(eje_X, mod_ridge0.coef_, color = 'purple')\n",
    "plt.title('Betas')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Valor de coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de los coeficientes\n",
    "\n",
    "Con la gráfica anterior podemos ver que la mayoría de los coeficientes están cercanos a cero.\n",
    "\n",
    "Esto nos indica que la mayoría de las variables no tienen una gran influencia en el modelo.\n",
    "\n",
    "Las variables con $\\beta_{i} \\notin [-1,1]$ son:\n",
    "\n",
    "|   Variable  | $\\beta$ |\n",
    "|:-----------:|:-------:|\n",
    "|    AtBat    |  -1.87  |\n",
    "|     Hits    |   6.58  |\n",
    "|    Walks    |   4.56  |\n",
    "|    Years    |   6.14  |\n",
    "|    CHmRun   |   1.59  |\n",
    "|    Errors   |   1.65  |\n",
    "|   League_N  |  51.95  |\n",
    "|  Division_W | -116.57 |\n",
    "| NewLeague_N |  -3.25  |\n",
    "\n",
    "\n",
    "En este caso $\\lambda = 0$ por lo que no importa el valor de los coeficientes ya que al multiplicarse por $\\lambda$ sus valores se anulan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) PREDICCIONES\n",
    "# Se hacen las predicciones con \"X_test\"\n",
    "Y_pred = mod_ridge0.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados de la predicción.\n",
    "plt.scatter(Y_test, Y_pred, color = 'blue')\n",
    "plt.title('Predicciones')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Salario estimado')\n",
    "plt.show()\n",
    "\n",
    "# Nota: No estamos graficando contra ninguna variable explicativa.\n",
    "#Los valores de las predicciones se graficaron contra el salario real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) EVALUACIÓN DEL MODELO CON lambda = 0\n",
    "#Calculamos el error cuadrático medio: $\\dfrac{\\displaystyle \\sum_{i = 1}^{n} (real_{i} − estimado_{i})^{2}}{n}$\n",
    "ECM0 = round(mean_squared_error(Y_test, Y_pred),3) \n",
    "print(ECM0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\lambda$ definida con _cross validation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) CONSTRUIR UN MODELO\n",
    "#Le pasamos como parámetro el vector con los diferentes valores de lambda para que\n",
    "#se elija la mejor con \"cross validation\"\n",
    "ridgecv = RidgeCV(alphas = lambdas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, Y_train)\n",
    "print('El valor de lambda encontrado con \"cross validation\" es: ',round(ridgecv.alpha_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificamos que el valor encontrado está en el vector de lambdas\n",
    "ridgecv.alpha_ in lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Se imprimen los valores de los coeficientes\n",
    "mod_ridgeCV = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "mod_ridgeCV.fit(X_train, Y_train)\n",
    "print(pd.Series(mod_ridgeCV.coef_, index = X.columns)) # Valor de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los valores de los coeficientes (betas).\n",
    "eje_X = range(1,len(mod_ridgeCV.coef_)+1,1)\n",
    "plt.scatter(eje_X, mod_ridgeCV.coef_, color = 'purple')\n",
    "plt.title('Betas')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Valor de coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de los coeficientes\n",
    "\n",
    "Con la gráfica anterior podemos ver que la mayoría de los coeficientes están cercanos a cero.\n",
    "\n",
    "Esto nos indica que la mayoría de las variables no tienen una gran influencia en el modelo.\n",
    "\n",
    "Las variables con $\\beta_{i} \\notin [-1,1]$ son:\n",
    "\n",
    "|   Variable  | $\\beta$ > 1 |  Variable  | $\\beta$ < -1 |\n",
    "|:-----------:|:-----------:|:----------:|:------------:|\n",
    "|     Hits    |     5.74    |    AtBat   |     -1.69    |\n",
    "|    Walks    |     4.20    |   HmRun   |     -2.40    |\n",
    "|    CHmRun   |     1.19    |    Years   |     -6.62    |\n",
    "|    Errors   |     1.70    | Division_W |    -117.51   |\n",
    "|   League_N  |    39.18    |      -     |       -      |\n",
    "| NewLeague_N |     4.62    |      -     |       -      |\n",
    "\n",
    "\n",
    "\n",
    "Las variables con $\\beta > 1$ son las que más aportan en el sueldo del jugador.\n",
    "\n",
    "El coeficiente de la variable _League_N_ es $39.18$. Podemos concluir que jugar en la liga nacional implica tener un mayor sueldo.\n",
    "\n",
    "Las variables con $\\beta < -1$ son las que impactan de manera negativa en el sueldo del jugador.\n",
    "\n",
    "El coeficiente de la variable _Division_W_ es $-117.51$. Podemos concluir que jugar en la división del oeste implica tener un menor sueldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) PREDICCIONES\n",
    "# Se hacen las predicciones con \"X_test\"\n",
    "Y_pred = mod_ridgeCV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados de la predicción.\n",
    "plt.scatter(Y_test, Y_pred, color = 'blue')\n",
    "plt.title('Predicciones')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Salario estimado')\n",
    "plt.show()\n",
    "\n",
    "# Nota: No estamos graficando contra ninguna variable explicativa.\n",
    "#Los valores de las predicciones se graficaron contra el salario real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) EVALUACIÓN DEL MODELO CON lambda ELEGIDA CON \"cross validation\"\n",
    "#Calculamos el error cuadrático medio: $\\dfrac{\\displaystyle \\sum_{i = 1}^{n} (real_{i} − estimado_{i})^{2}}{n}$\n",
    "ECMcv = round(mean_squared_error(Y_test, Y_pred),3) \n",
    "print(ECMcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos el error cuadrático medio (ECM) de cada modelo:\n",
    "print(\"ECM con lambda = 5 es: \",ECM5)\n",
    "print(\"ECM con lambda = 0 es: \",ECM0)\n",
    "print(\"ECM con lambda elegida es: \",ECMcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que el error cuadrático medio menor es el del modelo en el que se elige $\\lambda$ con _cross validation_.\n",
    "\n",
    "Elegimos ese modelo para seguir la evaluación.\n",
    "\n",
    "#### 7) EVALUACIÓN DEL MODELO ELEGIDO\n",
    "Veamos cómo se comporta el modelo:\n",
    "\n",
    "7.1 Calcular $R^{2}$ ajustada $ = 1 - \\dfrac{(1 - R^{2}) (n-1)}{n - p - 1}$, donde\n",
    "\n",
    "$R^{2}:$ R cuadrada de los datos\n",
    "\n",
    "$n:$ Número de datos para entrenar al modelo\n",
    "\n",
    "$p:$ Número de variables independientes\n",
    "\n",
    "7.2 Calcular los errores absolutos $(real - estimado)$ y graficarlos\n",
    "\n",
    "7.3 Calcular los errores relativos $\\left( \\dfrac{\\text{real - estimado}}{\\text{real}} \\right)$ y graficarlos\n",
    "\n",
    "7.4 Graficar valores estimados vs valores reales\n",
    "\n",
    "7.5 Calcular el error cuadrático: $(real − estimado)^{2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.1 Calcular R^2 ajustada\n",
    "r_cuadrada = r2_score(Y_test,Y_pred)\n",
    "print('R^2 = ',round(r_cuadrada,3)) #Porcentaje de los datos explicados por el modelo\n",
    "\n",
    "#R^2 ajustada\n",
    "n = len(Y_train)\n",
    "p = X_train.shape[1]\n",
    "r_cuad_aj = 1 - (((1-r_cuadrada)*(n-1))/(n-p-1))\n",
    "\n",
    "print('n = ',n)\n",
    "print('p = ',p)\n",
    "print('R^2_aj = ',round(r_cuad_aj,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de $R^{2}$ y $R_{aj}^{2}$\n",
    "\n",
    "Con $R^{2} =  0.44$ y $R_{aj}^{2} =  0.39$ vemos que el porcentaje de los datos explicados por el modelo es menor al $50\\%$.\n",
    "\n",
    "Recordemos que en el análisis de los valores de los coeficientes vimos que la mayoría de las variables no eran significativas para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.2 Calcular los errores absolutos (real - estimado) y graficarlos\n",
    "err_abs = Y_test-Y_pred\n",
    "\n",
    "plt.scatter(Y_test, err_abs, color = 'blue')\n",
    "plt.plot(Y_test, np.zeros(len(err_abs)), color = 'midnightblue') #Recta en Y = 0\n",
    "plt.title('Errores absolutos (real - estimado)')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Errores absolutos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.3 Calcular los errores relativos [(real - estimado)/real] y graficarlos\n",
    "err_rel = err_abs/Y_test\n",
    "\n",
    "plt.scatter(Y_test, err_rel, color = 'blue')\n",
    "plt.plot(Y_test, np.zeros(len(err_abs)), color = 'midnightblue') #Recta en Y = 0\n",
    "plt.title('Errores relativos [(real - estimado)/real]')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Errores relativos')\n",
    "plt.show()\n",
    "\n",
    "#Se tiene un mayor error en salarios bajos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.4 Graficar valores estimados vs valores reales\n",
    "eje_X = range(1,len(Y_test)+1)\n",
    "plt.plot(eje_X, Y_test, color = 'blue') #Recta de valores reales\n",
    "plt.plot(eje_X, Y_pred, color = 'green') #Recta de valores estimados\n",
    "plt.title('Valores estimados vs valores reales')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Salario')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente gráfica vamos a ordenar de menor a mayor los vectores para poder apreciar de mejor manera el comportamiento que se tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Los ordenamos de menor a mayor\n",
    "eje_X = range(1,len(Y_test)+1)\n",
    "plt.plot(eje_X, sorted(Y_test), color = 'blue') #Recta de valores reales\n",
    "plt.plot(eje_X, sorted(Y_pred), color = 'green') #Recta de valores estimados\n",
    "plt.title('Valores estimados vs valores reales')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Salario')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.5 Calcular el error cuadrático = (real − estimado)^2\n",
    "#print(np.around(err_abs,2))\n",
    "err_cuad = pow(err_abs,2)#Vector\n",
    "\n",
    "print(\"ECM con lambda = \",round(ridgecv.alpha_,3),\" es: \",ECMcv)\n",
    "\n",
    "#Graficamos los errores cuadráticos\n",
    "Y= np.repeat(ECMcv, len(err_cuad))\n",
    "plt.scatter(Y_test, err_cuad, color = 'blue')\n",
    "plt.plot(Y_test,Y , color = 'lime') #Recta en Y = error cuadrático medio\n",
    "plt.title('Errores cuadráticos: (real − estimado)^2')\n",
    "plt.xlabel('Ganancia real')\n",
    "plt.ylabel('Errores cuadráticos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan las librerías que se van a utilizar\n",
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para estandarizar las variables el parámetro \"normalize\" es verdadero.\n",
    "#Se define el máximo número de iteraciones en 10 mil\n",
    "lasso = Lasso(max_iter = 10000, normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for k in lambdas:\n",
    "    lasso.set_params(alpha = k)\n",
    "    lasso.fit(scale(X_train), Y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "np.shape(coefs)#Matriz con coeficientes asociadas a cada variable independiente y a cada valor de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esperamos que los coeficientes estimados sean cada vez más pequeños mientras lambda se hace mas grande.\n",
    "#Se espera que los coeficientes estimados sean más grandes si lambda es pequeña.\n",
    "\n",
    "#Grafiquemos\n",
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('pesos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) CONSTRUIR UN MODELO\n",
    "# Vamos a elegir lambda con \"cross validation\"\n",
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se imprimen los valores de los coeficientes\n",
    "print(pd.Series(lassocv.coef_, index = X.columns)) # Valor de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los valores de los coeficientes (betas).\n",
    "eje_X = range(1,len(lassocv.coef_)+1,1)\n",
    "plt.scatter(eje_X, lassocv.coef_, color = 'purple')\n",
    "plt.title('Betas')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Valor de coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de los coeficientes\n",
    "\n",
    "Al imprimir los valores de los coeficientes vemos que 6 variables son cero. Las variables que no aportan nada al modelo son:\n",
    "   1. HmRun: Número de home runs en 1986\n",
    "   2. Runs: Número de carreras en 1986\n",
    "   3. RBI: Número de carreras impulsadas en 1986, (Runs Batted In)\n",
    "   4. CAtBat: Número de veces al bat durante su carrera\n",
    "   5. CHits: Número de hits durante su carrera\n",
    "   6. Assists: Número de asistencias en 1986\n",
    "\n",
    "Con la gráfica anterior podemos ver que la mayoría de los coeficientes son o están cercanos a cero. Esto nos indica que la mayoría de las variables no tienen una gran influencia en el modelo.\n",
    "\n",
    "Las variables con $\\beta_{i} \\notin [-1,1]$ son:\n",
    "\n",
    "|   Variable  | $\\beta$ > 1 |  Variable  | $\\beta$ < -1 |\n",
    "|:-----------:|:-----------:|:----------:|:------------:|\n",
    "|     Hits    |     6.11    |    AtBat   |     -1.55    |\n",
    "|    Walks    |     3.66    |    Years   |     -5.71    |\n",
    "|    CHmRun   |    1.006    | Division_W |    -113.89   |\n",
    "|    Errors   |     1.23    |      -     |       -      |\n",
    "|   League_N  |    28.51    |      -     |       -      |\n",
    "| NewLeague_N |    11.22    |      -     |       -      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué pasa con _League_N, Division_W_ y _NewLeague_N_?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables con $\\beta > 1$ son las que más aportan en el sueldo del jugador.\n",
    "\n",
    "El coeficiente de la variable _League_N_ es $28.51$ y el de _NewLeague_N_ es $11.22$. Podemos concluir que jugar en la liga nacional implica tener un mayor sueldo.\n",
    "\n",
    "Las variables con $\\beta < -1$ son las que impactan de manera negativa en el sueldo del jugador.\n",
    "\n",
    "El coeficiente de la variable _Division_W_ es $-113.89$. Podemos concluir que jugar en la división del oeste implica tener un menor sueldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) PREDICCIONES\n",
    "# Se hacen las predicciones con \"X_test\"\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "print('El valor de lambda encontrado con \"cross validation\" es: ',round(lassocv.alpha_,3))\n",
    "lasso.fit(X_train, Y_train)\n",
    "Y_pred = lasso.predict(X_test)\n",
    "\n",
    "##Recordamos que el lambda encotrado en Ridge Regression fue de 0.012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados de la predicción.\n",
    "plt.scatter(Y_test, Y_pred, color = 'blue')\n",
    "plt.title('Predicciones')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Salario estimado')\n",
    "plt.show()\n",
    "\n",
    "# Nota: No estamos graficando contra ninguna variable explicativa.\n",
    "#Los valores de las predicciones se graficaron contra el salario real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) EVALUACIÓN DEL MODELO\n",
    "Veamos cómo se comporta el modelo:\n",
    "\n",
    "7.1 Calcular $R^{2}$ ajustada $ = 1 - \\dfrac{(1 - R^{2}) (n-1)}{n - p - 1}$, donde\n",
    "\n",
    "$R^{2}:$ R cuadrada de los datos\n",
    "\n",
    "$n:$ Número de datos para entrenar al modelo\n",
    "\n",
    "$p:$ Número de variables independientes\n",
    "\n",
    "7.2 Calcular los errores absolutos $(real - estimado)$ y graficarlos\n",
    "\n",
    "7.3 Calcular los errores relativos $\\left( \\dfrac{\\text{real - estimado}}{\\text{real}} \\right)$ y graficarlos\n",
    "\n",
    "7.4 Graficar valores estimados vs valores reales\n",
    "\n",
    "7.5 Calcular el error cuadrático: $(real − estimado)^{2}$\n",
    "\n",
    "7.6 Calcular el error cuadrático medio: $\\dfrac{\\displaystyle \\sum_{i = 1}^{n} (real_{i} − estimado_{i})^{2}}{n}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.1 Calcular R^2 ajustada\n",
    "r_cuadrada = r2_score(Y_test,Y_pred)\n",
    "print('R^2 = ',round(r_cuadrada,3)) #Porcentaje de los datos explicados por el modelo\n",
    "\n",
    "#R^2 ajustada\n",
    "n = len(Y_train)\n",
    "p = X_train.shape[1]\n",
    "r_cuad_aj = 1 - (((1-r_cuadrada)*(n-1))/(n-p-1))\n",
    "\n",
    "print('n = ',n)\n",
    "print('p = ',p)\n",
    "print('R^2_aj = ',round(r_cuad_aj,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.1 Calcular R^2 ajustada\n",
    "r_cuadrada = r2_score(Y_test,Y_pred)\n",
    "print('R^2 = ',round(r_cuadrada,3)) #Porcentaje de los datos explicados por el modelo\n",
    "\n",
    "#R^2 ajustada\n",
    "n = len(Y_train)\n",
    "p = 13 #Número de variables != 0\n",
    "r_cuad_aj = 1 - (((1-r_cuadrada)*(n-1))/(n-p-1))\n",
    "\n",
    "print('n = ',n)\n",
    "print('p = ',p)\n",
    "print('R^2_aj = ',round(r_cuad_aj,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de $R^{2}$ y $R_{aj}^{2}$\n",
    "\n",
    "Con $R^{2} =  0.45$ y $R_{aj}^{2} =  0.4$ vemos que el procentaje de los datos explicados por el modelo es menor al $50\\%$.\n",
    "\n",
    "Notamos que el porcentaje es mayor comparado con los valores obtenidos en _Ridge Regression_.\n",
    "\n",
    "Recordemos que nuestros datos tienen 19 variables predictoras. En el análisis de los valores de los coeficientes vimos que, de dichas variables:\n",
    "\n",
    "   - 6 tienen coeficientes iguales a cero\n",
    "   - 6 variables tienen coeficientes mayores a 1\n",
    "   - 3 tienen coeficientes menores a -1\n",
    "   \n",
    "Las 4 restantes tienen coeficientes entre -1 y 1, por lo que decimos que no son significativas para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.2 Calcular los errores absolutos (real - estimado) y graficarlos\n",
    "err_abs = Y_test-Y_pred\n",
    "\n",
    "plt.scatter(Y_test, err_abs, color = 'blue')\n",
    "plt.plot(Y_test, np.zeros(len(err_abs)), color = 'midnightblue') #Recta en Y = 0\n",
    "plt.title('Errores absolutos (real - estimado)')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Errores absolutos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.3 Calcular los errores relativos [(real - estimado)/real] y graficarlos\n",
    "err_rel = err_abs/Y_test\n",
    "\n",
    "plt.scatter(Y_test, err_rel, color = 'blue')\n",
    "plt.plot(Y_test, np.zeros(len(err_abs)), color = 'midnightblue') #Recta en Y = 0\n",
    "plt.title('Errores relativos [(real - estimado)/real]')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Errores relativos')\n",
    "plt.show()\n",
    "\n",
    "#Se tiene un mayor error en salarios bajos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.4 Graficar valores estimados vs valores reales\n",
    "eje_X = range(1,len(Y_test)+1)\n",
    "plt.plot(eje_X, Y_test, color = 'blue') #Recta de valores reales\n",
    "plt.plot(eje_X, Y_pred, color = 'green') #Recta de valores estimados\n",
    "plt.title('Valores estimados vs valores reales')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Salario')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Los ordenamos de menor a mayor\n",
    "eje_X = range(1,len(Y_test)+1)\n",
    "plt.plot(eje_X, sorted(Y_test), color = 'blue') #Recta de valores reales\n",
    "plt.plot(eje_X, sorted(Y_pred), color = 'green') #Recta de valores estimados\n",
    "plt.title('Valores estimados vs valores reales')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Salario')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.5 Calcular el error cuadrático = (real − estimado)^2\n",
    "#print(np.around(err_abs,2))\n",
    "err_cuad = pow(err_abs,2)#Vector\n",
    "\n",
    "#7.6 Calcular el error cuadrático medio = (1/n) * \\sum (real − estimado)^2\n",
    "'''\n",
    "Indica qué tan cerca está la línea de la regresión lineal de los valores estimados.\n",
    "i) Se elevan al cuadrado los errores absolutos.\n",
    "ii) Se suman.\n",
    "iii) Se divide el resultado entre el número de datos estimados.\n",
    "'''\n",
    "ECMlasso = round(mean_squared_error(Y_test, Y_pred),3)\n",
    "print('Error cuadrático medio = ',round(ECMlasso,2))\n",
    "print('Raíz cuadrada del error cuadrático medio = ',round(math.sqrt(ECMlasso),2))#Raíz cuadrada del error cuadrático medio\n",
    "\n",
    "#Graficamos los errores cuadráticos\n",
    "Y= np.repeat(ECMcv, len(err_cuad))\n",
    "plt.scatter(Y_test, err_cuad, color = 'blue')\n",
    "plt.plot(Y_test,Y , color = 'lime') #Recta en Y = error cuadrático medio\n",
    "plt.title('Errores cuadráticos: (real − estimado)^2')\n",
    "plt.xlabel('Ganancia real')\n",
    "plt.ylabel('Errores cuadráticos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos el error cuadrático medio (ECM) de ambas regresiones:\n",
    "# La comparación se hace tomando el modelo hecho con la lambda elegida con \"cross validation\"\n",
    "if ECMlasso < ECMcv:\n",
    "    print(\"ECM LASSO = \",ECMlasso,\" < \",ECMcv,\" = ECM Ridge \\nElegir LASSO Regression\")\n",
    "elif ECMlasso > ECMcv:\n",
    "    print(\"ECM LASSO = \",ECMlasso,\" > \",ECMcv,\" = ECM Ridge \\nElegir Ridge Regression\")\n",
    "else:\n",
    "    print(\"Ambas regresiones tienen el mismo ECM = \",ECMlasso,\"\\nElegir cualquier regresión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Al comparar ambos modelos con el error cuadrático medio, se elige _LASSO Regression_.\n",
    "\n",
    "Los coeficientes de cada modelo son muy similares. Podemos observar que _HmRun_ es la variable en la que más se difiere ya en en el caso de _Ridge Regression_ $\\beta = -2.4$ y para _LASSO Regression_ $\\beta = 0$.\n",
    "\n",
    "En _LASSO Regression_ se hacen cero las variables que tienen coeficientes casi cero en _Ridge Regression_.\n",
    "\n",
    "_Nota:_ En Ciencia de Datos, lo que importa son las decisiones que se toman con respecto a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué pasa si quitamos las variables que LASSO hace cero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el nuevo data frame\n",
    "X = X.drop(['HmRun','Runs','RBI','CAtBat','CHits','Assists'], axis = 1)\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de los datos\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las variables que se van a utilizar\n",
    "ridge = Ridge(normalize = True)#Para estandarizar las variables el parámetro \"normalize\" es verdadero\n",
    "coefs = []\n",
    "\n",
    "#Se llena la matriz con coeficientes asociadas a cada variable independiente y a cada valor de lambda\n",
    "for k in lambdas:\n",
    "    ridge.set_params(alpha = k)#Se toman los valores de lambda\n",
    "    ridge.fit(X_train, Y_train)#Se ajusta el modelo\n",
    "    coefs.append(ridge.coef_)#Se generan los coeficientes correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) CONSTRUIR UN MODELO\n",
    "#Le pasamos como parámetro el vector con los diferentes valores de lambda para que\n",
    "#se elija la mejor con \"cross validation\"\n",
    "ridgecv = RidgeCV(alphas = lambdas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, Y_train)\n",
    "print('El valor de lambda encontrado con \"cross validation\" es: ',round(ridgecv.alpha_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se imprimen los valores de los coeficientes\n",
    "mod_ridgeCV = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "mod_ridgeCV.fit(X_train, Y_train)\n",
    "print(pd.Series(mod_ridgeCV.coef_, index = X.columns)) # Valor de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los valores de los coeficientes (betas).\n",
    "eje_X = range(1,len(mod_ridgeCV.coef_)+1,1)\n",
    "plt.scatter(eje_X, mod_ridgeCV.coef_, color = 'purple')\n",
    "plt.title('Betas')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Valor de coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) PREDICCIONES\n",
    "# Se hacen las predicciones con \"X_test\"\n",
    "Y_pred = mod_ridgeCV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados de la predicción.\n",
    "plt.scatter(Y_test, Y_pred, color = 'blue')\n",
    "plt.title('Predicciones')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Salario estimado')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) EVALUACIÓN DEL MODELO CON lambda ELEGIDA CON \"cross validation\"\n",
    "#Calculamos el error cuadrático medio: $\\dfrac{\\displaystyle \\sum_{i = 1}^{n} (real_{i} − estimado_{i})^{2}}{n}$\n",
    "ECM = round(mean_squared_error(Y_test, Y_pred),3) \n",
    "print(ECM)\n",
    "\n",
    "#7.1 Calcular R^2 ajustada\n",
    "r_cuadrada = r2_score(Y_test,Y_pred)\n",
    "print('R^2 = ',round(r_cuadrada,3)) #Porcentaje de los datos explicados por el modelo\n",
    "\n",
    "#R^2 ajustada\n",
    "n = len(Y_train)\n",
    "p = X_train.shape[1]\n",
    "r_cuad_aj = 1 - (((1-r_cuadrada)*(n-1))/(n-p-1))\n",
    "\n",
    "print('n = ',n)\n",
    "print('p = ',p)\n",
    "print('R^2_aj = ',round(r_cuad_aj,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay una mejora en la $R^{2}_{ajustada}$, comparada con el modelo con las 19 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) CONSTRUIR UN MODELO\n",
    "# Vamos a elegir lambda con \"cross validation\"\n",
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, Y_train)\n",
    "\n",
    "# Se grafican los valores de los coeficientes (betas).\n",
    "eje_X = range(1,len(lassocv.coef_)+1,1)\n",
    "plt.scatter(eje_X, lassocv.coef_, color = 'purple')\n",
    "plt.title('Betas')\n",
    "plt.xlabel('Índices')\n",
    "plt.ylabel('Valor de coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la función LassoCV(), se definen las $\\alpha$ como _None_ (alphas = None), con este comando la función define automáticamente los valores de $\\alpha$ que se van a utilizar. Ver [sklearn.linear_model.LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se imprimen los valores de los coeficientes\n",
    "print(pd.Series(lassocv.coef_, index = X.columns)) # Valor de los coeficientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna variable tiene coeficiente igual a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) PREDICCIONES\n",
    "# Se hacen las predicciones con \"X_test\"\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "print('El valor de lambda encontrado con \"cross validation\" es: ',round(lassocv.alpha_,3))\n",
    "lasso.fit(X_train, Y_train)\n",
    "Y_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados de la predicción.\n",
    "plt.scatter(Y_test, Y_pred, color = 'blue')\n",
    "plt.title('Predicciones')\n",
    "plt.xlabel('Salario real')\n",
    "plt.ylabel('Salario estimado')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) EVALUACIÓN DEL MODELO\n",
    "#7.1 Calcular R^2 ajustada\n",
    "r_cuadrada = r2_score(Y_test,Y_pred)\n",
    "print('R^2 = ',round(r_cuadrada,3)) #Porcentaje de los datos explicados por el modelo\n",
    "\n",
    "#R^2 ajustada\n",
    "n = len(Y_train)\n",
    "p = X_train.shape[1]\n",
    "r_cuad_aj = 1 - (((1-r_cuadrada)*(n-1))/(n-p-1))\n",
    "\n",
    "print('n = ',n)\n",
    "print('p = ',p)\n",
    "print('R^2_aj = ',round(r_cuad_aj,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Debido a que LASSO permite que los coeficientes puedan valer cero, se pueden eliminar variables que no son representativas para el modelo. Es por ello que al eliminar las variables no hay cambio en la $R^{2}_{ajustada}$.\n",
    "\n",
    "En cambio en el modelo de _Ridge Regression_ se observa una mejora en el valor de $R^{2}_{ajustada}$ al eliminar las variables eliminadas por LASSO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
