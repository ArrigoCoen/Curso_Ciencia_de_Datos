{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Logistic Regression\n",
    "\n",
    "Vamos a considerar los datos de [Kaggle](https://www.kaggle.com/c/tabular-playground-series-jun-2021/code?competitionId=26480), para ajustar un modelo de regresión logística que haga predicciones sobre la categoría.\n",
    "\n",
    "Ideas para este ajuste son de [aquí](https://www.kaggle.com/whenthetidegoesout/june-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "Para ejecutar este comando es necesario dar la ubicación del archivo `train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>199995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>199996</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>199997</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>199998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>199999</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0            0          0          0          6          1          0   \n",
       "1            1          0          0          0          0          0   \n",
       "2            2          0          0          0          0          0   \n",
       "3            3          0          0          7          0          1   \n",
       "4            4          1          0          0          0          0   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "199995  199995          0          1          6          0          1   \n",
       "199996  199996          0          2          0          0          1   \n",
       "199997  199997          1          2          0          0          0   \n",
       "199998  199998          0          0          2          0          2   \n",
       "199999  199999          5          4          0         10          0   \n",
       "\n",
       "        feature_5  feature_6  feature_7  feature_8  ...  feature_66  \\\n",
       "0               0          0          0          7  ...           0   \n",
       "1               0          0          0          0  ...           2   \n",
       "2               1          0          3          0  ...           0   \n",
       "3               5          2          2          0  ...           0   \n",
       "4               0          0          0          0  ...           0   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "199995         32          0          6          0  ...           0   \n",
       "199996          0          0          0          0  ...           0   \n",
       "199997          2          0          1          8  ...           1   \n",
       "199998          1          0          0          3  ...           0   \n",
       "199999          1          0          0         12  ...           0   \n",
       "\n",
       "        feature_67  feature_68  feature_69  feature_70  feature_71  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           1           0   \n",
       "3                4           0           2           2           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "199995           1           1           0           0           0   \n",
       "199996           0           0           0           0           0   \n",
       "199997           0           1           1           1           0   \n",
       "199998           0           3           2           1           0   \n",
       "199999           0           2           1           0           0   \n",
       "\n",
       "        feature_72  feature_73  feature_74   target  \n",
       "0                2           0           0  Class_6  \n",
       "1                0           1           0  Class_6  \n",
       "2                0           0           0  Class_2  \n",
       "3                4           3           0  Class_8  \n",
       "4                0           0           0  Class_2  \n",
       "...            ...         ...         ...      ...  \n",
       "199995           4           1           0  Class_6  \n",
       "199996           0           0           0  Class_6  \n",
       "199997           1           0           0  Class_8  \n",
       "199998           0           1           0  Class_7  \n",
       "199999           2           3           1  Class_8  \n",
       "\n",
       "[200000 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf = pd.read_csv('tabular-playground-series-jun-2021/train.csv')\n",
    "dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0          0          0          6          1          0          0   \n",
       "1   1          0          0          0          0          0          0   \n",
       "2   2          0          0          0          0          0          1   \n",
       "3   3          0          0          7          0          1          5   \n",
       "4   4          1          0          0          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_66  feature_67  feature_68  \\\n",
       "0          0          0          7  ...           0           0           0   \n",
       "1          0          0          0  ...           2           0           0   \n",
       "2          0          3          0  ...           0           0           0   \n",
       "3          2          2          0  ...           0           4           0   \n",
       "4          0          0          0  ...           0           0           0   \n",
       "\n",
       "   feature_69  feature_70  feature_71  feature_72  feature_73  feature_74  \\\n",
       "0           0           0           0           2           0           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           2           2           0           4           3           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "    target  \n",
       "0  Class_6  \n",
       "1  Class_6  \n",
       "2  Class_2  \n",
       "3  Class_8  \n",
       "4  Class_2  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 77 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   id          200000 non-null  int64 \n",
      " 1   feature_0   200000 non-null  int64 \n",
      " 2   feature_1   200000 non-null  int64 \n",
      " 3   feature_2   200000 non-null  int64 \n",
      " 4   feature_3   200000 non-null  int64 \n",
      " 5   feature_4   200000 non-null  int64 \n",
      " 6   feature_5   200000 non-null  int64 \n",
      " 7   feature_6   200000 non-null  int64 \n",
      " 8   feature_7   200000 non-null  int64 \n",
      " 9   feature_8   200000 non-null  int64 \n",
      " 10  feature_9   200000 non-null  int64 \n",
      " 11  feature_10  200000 non-null  int64 \n",
      " 12  feature_11  200000 non-null  int64 \n",
      " 13  feature_12  200000 non-null  int64 \n",
      " 14  feature_13  200000 non-null  int64 \n",
      " 15  feature_14  200000 non-null  int64 \n",
      " 16  feature_15  200000 non-null  int64 \n",
      " 17  feature_16  200000 non-null  int64 \n",
      " 18  feature_17  200000 non-null  int64 \n",
      " 19  feature_18  200000 non-null  int64 \n",
      " 20  feature_19  200000 non-null  int64 \n",
      " 21  feature_20  200000 non-null  int64 \n",
      " 22  feature_21  200000 non-null  int64 \n",
      " 23  feature_22  200000 non-null  int64 \n",
      " 24  feature_23  200000 non-null  int64 \n",
      " 25  feature_24  200000 non-null  int64 \n",
      " 26  feature_25  200000 non-null  int64 \n",
      " 27  feature_26  200000 non-null  int64 \n",
      " 28  feature_27  200000 non-null  int64 \n",
      " 29  feature_28  200000 non-null  int64 \n",
      " 30  feature_29  200000 non-null  int64 \n",
      " 31  feature_30  200000 non-null  int64 \n",
      " 32  feature_31  200000 non-null  int64 \n",
      " 33  feature_32  200000 non-null  int64 \n",
      " 34  feature_33  200000 non-null  int64 \n",
      " 35  feature_34  200000 non-null  int64 \n",
      " 36  feature_35  200000 non-null  int64 \n",
      " 37  feature_36  200000 non-null  int64 \n",
      " 38  feature_37  200000 non-null  int64 \n",
      " 39  feature_38  200000 non-null  int64 \n",
      " 40  feature_39  200000 non-null  int64 \n",
      " 41  feature_40  200000 non-null  int64 \n",
      " 42  feature_41  200000 non-null  int64 \n",
      " 43  feature_42  200000 non-null  int64 \n",
      " 44  feature_43  200000 non-null  int64 \n",
      " 45  feature_44  200000 non-null  int64 \n",
      " 46  feature_45  200000 non-null  int64 \n",
      " 47  feature_46  200000 non-null  int64 \n",
      " 48  feature_47  200000 non-null  int64 \n",
      " 49  feature_48  200000 non-null  int64 \n",
      " 50  feature_49  200000 non-null  int64 \n",
      " 51  feature_50  200000 non-null  int64 \n",
      " 52  feature_51  200000 non-null  int64 \n",
      " 53  feature_52  200000 non-null  int64 \n",
      " 54  feature_53  200000 non-null  int64 \n",
      " 55  feature_54  200000 non-null  int64 \n",
      " 56  feature_55  200000 non-null  int64 \n",
      " 57  feature_56  200000 non-null  int64 \n",
      " 58  feature_57  200000 non-null  int64 \n",
      " 59  feature_58  200000 non-null  int64 \n",
      " 60  feature_59  200000 non-null  int64 \n",
      " 61  feature_60  200000 non-null  int64 \n",
      " 62  feature_61  200000 non-null  int64 \n",
      " 63  feature_62  200000 non-null  int64 \n",
      " 64  feature_63  200000 non-null  int64 \n",
      " 65  feature_64  200000 non-null  int64 \n",
      " 66  feature_65  200000 non-null  int64 \n",
      " 67  feature_66  200000 non-null  int64 \n",
      " 68  feature_67  200000 non-null  int64 \n",
      " 69  feature_68  200000 non-null  int64 \n",
      " 70  feature_69  200000 non-null  int64 \n",
      " 71  feature_70  200000 non-null  int64 \n",
      " 72  feature_71  200000 non-null  int64 \n",
      " 73  feature_72  200000 non-null  int64 \n",
      " 74  feature_73  200000 non-null  int64 \n",
      " 75  feature_74  200000 non-null  int64 \n",
      " 76  target      200000 non-null  object\n",
      "dtypes: int64(76), object(1)\n",
      "memory usage: 117.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "feature_0     0\n",
       "feature_1     0\n",
       "feature_2     0\n",
       "feature_3     0\n",
       "             ..\n",
       "feature_71    0\n",
       "feature_72    0\n",
       "feature_73    0\n",
       "feature_74    0\n",
       "target        0\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que:\n",
    "    - Todas las columnas de variables `X` son numéricas\n",
    "    - La columna `y` es del tipo `object`\n",
    "    - No tenemos nulos\n",
    "    \n",
    "Ahora analicemos el número de observaciones por categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Class_1     9118\n",
       "Class_2    24431\n",
       "Class_3    14798\n",
       "Class_4     4704\n",
       "Class_5     3064\n",
       "Class_6    51811\n",
       "Class_7    14769\n",
       "Class_8    51763\n",
       "Class_9    25542\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_a = dataf.groupby('target').count()['id']\n",
    "viz_a.plot(kind='bar', title='Count of Tartgets', figsize=(15, 12))\n",
    "dataf.groupby('target').count()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini sample y Separación train/test\n",
    "Tenemos `200000` renglones, así que para agilizar los cálculos usaremos una mini muestra de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.read_csv('tabular-playground-series-jun-2021/train.csv')\n",
    "size_of_mini_sample = 5000\n",
    "dataf = dataf.sample(n=size_of_mini_sample, random_state=42) # también se podría usar una fracción con `frac=0.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataf.target\n",
    "X = dataf.drop('target', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.read_csv('tabular-playground-series-jun-2021/train.csv')\n",
    "# size_of_mini_sample = 10000\n",
    "# dataf = dataf.sample(n=size_of_mini_sample, random_state=42) # también se podría usar una fracción con `frac=0.4`\n",
    "y = dataf.target\n",
    "X = dataf.drop('target', axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Class_6\n",
       "1         Class_6\n",
       "2         Class_2\n",
       "3         Class_8\n",
       "4         Class_2\n",
       "           ...   \n",
       "199995    Class_6\n",
       "199996    Class_6\n",
       "199997    Class_8\n",
       "199998    Class_7\n",
       "199999    Class_8\n",
       "Name: target, Length: 200000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>199995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>199996</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>199997</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>199998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>199999</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0            0          0          0          6          1          0   \n",
       "1            1          0          0          0          0          0   \n",
       "2            2          0          0          0          0          0   \n",
       "3            3          0          0          7          0          1   \n",
       "4            4          1          0          0          0          0   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "199995  199995          0          1          6          0          1   \n",
       "199996  199996          0          2          0          0          1   \n",
       "199997  199997          1          2          0          0          0   \n",
       "199998  199998          0          0          2          0          2   \n",
       "199999  199999          5          4          0         10          0   \n",
       "\n",
       "        feature_5  feature_6  feature_7  feature_8  ...  feature_65  \\\n",
       "0               0          0          0          7  ...           3   \n",
       "1               0          0          0          0  ...           0   \n",
       "2               1          0          3          0  ...           8   \n",
       "3               5          2          2          0  ...           0   \n",
       "4               0          0          0          0  ...           0   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "199995         32          0          6          0  ...           1   \n",
       "199996          0          0          0          0  ...           0   \n",
       "199997          2          0          1          8  ...           4   \n",
       "199998          1          0          0          3  ...           0   \n",
       "199999          1          0          0         12  ...           2   \n",
       "\n",
       "        feature_66  feature_67  feature_68  feature_69  feature_70  \\\n",
       "0                0           0           0           0           0   \n",
       "1                2           0           0           0           0   \n",
       "2                0           0           0           0           1   \n",
       "3                0           4           0           2           2   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "199995           0           1           1           0           0   \n",
       "199996           0           0           0           0           0   \n",
       "199997           1           0           1           1           1   \n",
       "199998           0           0           3           2           1   \n",
       "199999           0           0           2           1           0   \n",
       "\n",
       "        feature_71  feature_72  feature_73  feature_74  \n",
       "0                0           2           0           0  \n",
       "1                0           0           1           0  \n",
       "2                0           0           0           0  \n",
       "3                0           4           3           0  \n",
       "4                0           0           0           0  \n",
       "...            ...         ...         ...         ...  \n",
       "199995           0           4           1           0  \n",
       "199996           0           0           0           0  \n",
       "199997           0           1           0           0  \n",
       "199998           0           0           1           0  \n",
       "199999           0           2           3           1  \n",
       "\n",
       "[200000 rows x 76 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.29\n",
      "Train f1 Score:  0.29268666666666665\n",
      "Test f1 Score:  0.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_1       0.00      0.00      0.00      2262\n",
      "     Class_2       0.00      0.00      0.00      6141\n",
      "     Class_3       0.00      0.00      0.00      3692\n",
      "     Class_4       0.00      0.00      0.00      1206\n",
      "     Class_5       0.00      0.00      0.00       785\n",
      "     Class_6       0.27      0.55      0.36     12916\n",
      "     Class_7       0.00      0.00      0.00      3742\n",
      "     Class_8       0.31      0.58      0.41     12991\n",
      "     Class_9       0.00      0.00      0.00      6265\n",
      "\n",
      "    accuracy                           0.29     50000\n",
      "   macro avg       0.06      0.13      0.09     50000\n",
      "weighted avg       0.15      0.29      0.20     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.25, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "print(\"Train f1 Score: \",f1_score(y_train, y_pred_train,average='micro'))\n",
    "print(\"Test f1 Score: \",f1_score(y_test, y_pred_test,average='micro'))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo visto tenemos varias cosas que resolver.\n",
    "Empecemos utilizando `Pipelines` para mejorar el ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('scalar2',StandardScaler()),\n",
    "#                      ('pca2',PCA(n_components=2)),\n",
    "                     ('dt_classifier',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scalar2', StandardScaler()),\n",
       "                ('dt_classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter C for estimator Pipeline(steps=[('scalar2', StandardScaler()),\n                ('dt_classifier', LogisticRegression())]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 141, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 53, in _set_params\n    super().set_params(**params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 249, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter C for estimator Pipeline(steps=[('scalar2', StandardScaler()),\n                ('dt_classifier', LogisticRegression())]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3e467ed56c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter C for estimator Pipeline(steps=[('scalar2', StandardScaler()),\n                ('dt_classifier', LogisticRegression())]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "best_clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(),LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.340335"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe,X,y,cv=5,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'estimator__logisticregression__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'estimator__logisticregression__C' : np.logspace(-4, 4, 20),\n",
    "    'estimator__logisticregression__solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'estimator__logisticregression__max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter estimator for estimator Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 141, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 53, in _set_params\n    super().set_params(**params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 249, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter estimator for estimator Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f85a306994ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter estimator for estimator Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__standardscaler', 'estimator__logisticregression', 'estimator__standardscaler__copy', 'estimator__standardscaler__with_mean', 'estimator__standardscaler__with_std', 'estimator__logisticregression__C', 'estimator__logisticregression__class_weight', 'estimator__logisticregression__dual', 'estimator__logisticregression__fit_intercept', 'estimator__logisticregression__intercept_scaling', 'estimator__logisticregression__l1_ratio', 'estimator__logisticregression__max_iter', 'estimator__logisticregression__multi_class', 'estimator__logisticregression__n_jobs', 'estimator__logisticregression__penalty', 'estimator__logisticregression__random_state', 'estimator__logisticregression__solver', 'estimator__logisticregression__tol', 'estimator__logisticregression__verbose', 'estimator__logisticregression__warm_start', 'estimator', 'iid', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-04, 1.e+04])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logModel = LogisticRegression(solver='saga',random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [ {   \n",
    "    'penalty' : ['elasticnet'],\n",
    "    'C' : np.logspace(-4, 4, 2),\n",
    "    'l1_ratio' : [.5],\n",
    "#     'solver' : ['lbfgs'],\n",
    "    'max_iter' : [100]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  7.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  7.1min finished\n"
     ]
    }
   ],
   "source": [
    "best_clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Accuracy - : {best_clf.score(X,y):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=74)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative explained variance across all PCs\n",
    "cum_exp_var = []\n",
    "var_exp = 0\n",
    "for i in pca.explained_variance_ratio_:\n",
    "    var_exp += i\n",
    "    cum_exp_var.append(var_exp)\n",
    "\n",
    "# Plot cumulative explained variance for all PCs\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.bar(range(1,75), cum_exp_var)\n",
    "ax.set_xlabel('# Principal Components')\n",
    "ax.set_ylabel('% Cumulative Variance Explained');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.25,random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "    \n",
    "print(\"Train f1 Score: \",f1_score(y_train, y_pred_train,average='micro'))\n",
    "print(\"Test f1 Score: \",f1_score(y_test, y_pred_test,average='micro'))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "\n",
    "acc = []\n",
    "# Will take some time\n",
    "from sklearn import metrics\n",
    "for i in range(1,40):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
    "    yhat = neigh.predict(X_test)\n",
    "    acc.append(metrics.accuracy_score(y_test, yhat))\n",
    "    \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('accuracy vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "print(\"Maximum accuracy:-\",max(acc),\"at K =\",acc.index(max(acc)))\n",
    "\n",
    "acc = []\n",
    "# Will take some time\n",
    "from sklearn import metrics\n",
    "for i in range(41,70):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
    "    yhat = neigh.predict(X_test)\n",
    "    acc.append(metrics.accuracy_score(y_test, yhat))\n",
    "    \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(41,70),acc,color = 'blue',linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('accuracy vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "print(\"Maximum accuracy:-\",max(acc),\"at K =\",acc.index(max(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan las librerías que se van a utilizar en ambos ejemplos\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures  # <------ library to perform Polynomial Regression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "pd.set_option('display.max_rows', 90) # by default is 10, if change to None print ALL\n",
    "pd.set_option('display.max_columns', 90) # by default is 10, if change to None print ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) EXTRAER DATOS\n",
    "# Los datos pueden encontrarse en diferentes formatos, en nuestro caso están en formato csv.\n",
    "\n",
    "# Se carga la base de datos\n",
    "train = pd.read_csv('train.csv') #Se encuentra en la misma carpeta que el jupyter notebook\n",
    "test = pd.read_csv('test.csv') #Se encuentra en la misma carpeta que el jupyter notebook\n",
    "print(train.shape) \n",
    "print(test.shape) \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate of some columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos a eleminar las columnas que tienen más del 50% de sus valores como nulas en train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_plus_50percent_null = train.isnull().sum()[train.isnull().sum()>train.shape[0]/2]\n",
    "col_plus_50percent_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos que también hay casi las mismas columnas en test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()[test.isnull().sum()>test.shape[0]/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces nos queda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['PoolQC','MiscFeature','Alley','Fence']\n",
    "train = train.drop(features_drop, axis=1)\n",
    "test  =  test.drop(features_drop, axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprovemos que ya no tenemos esas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_plus_50percent_null = train.isnull().sum()[train.isnull().sum()>train.shape[0]/2]\n",
    "col_plus_50percent_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()[test.isnull().sum()>test.shape[0]/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de variables\n",
    "\n",
    "Separemos las variables en `X_train`, `X_test`, `y_train`, `y_test`, al igual que elijamos que columnas son numericas, ordinales y nominales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical = train.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical.remove('Id')\n",
    "numerical.remove('SalePrice')\n",
    "\n",
    "nominal = train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "#           \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "#           \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "ordinal = []\n",
    "\n",
    "X = train[nominal + ordinal + numerical] #LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "X_REAL_test = test[nominal + ordinal + numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines auxiliares\n",
    "\n",
    "Para separar mejor el procesamiento de nuestros datos, utilizamos tres pipelines auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline datos ordinales\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Pipeline datos nominales\n",
    "nominal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Pipeline datos numéricos\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Pegado de los tres pipelines\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "    (\"ordinal_preprocessor\", ordinal_pipeline, ordinal),\n",
    "    (\"numerical_preprocessor\", numerical_pipeline, numerical)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente agregamos todo en un solo pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_features = preprocessing_pipeline.fit_transform(train_features)\n",
    "\n",
    "# ML_model = Lasso(alpha=190)\n",
    "# ML_model = Ridge(alpha=20)\n",
    "ML_model = LinearRegression()\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessing_pipeline),\n",
    "    (\"estimator\", ML_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pipeline.fit(X_train, y_train)\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score:', r2_score(y_test, y_pred)) \n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de archivo para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_REAL_test = complete_pipeline.predict(X_REAL_test)\n",
    "\n",
    "pred=pd.DataFrame(y_REAL_test)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para subir el archivo es [aquí](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONA PIPELINE LASSO WITH \n",
    "\n",
    "numerical = train.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical.remove('Id')\n",
    "numerical.remove('SalePrice')\n",
    "\n",
    "nominal = train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "          \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "          \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "ordinal = []\n",
    "\n",
    "\n",
    "X = train[nominal + ordinal + numerical] #LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# here we are going to instantiate a ColumnTransformer object with a list of tuples\n",
    "# each of which has a the name of the preprocessor\n",
    "# the transformation pipeline (could be a transformer)\n",
    "# and the list of column names we wish to transform\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "    (\"ordinal_preprocessor\", ordinal_pipeline, ordinal),\n",
    "    (\"numerical_preprocessor\", numerical_pipeline, numerical)\n",
    "])\n",
    "\n",
    "## If you want to test this pipeline run the following code\n",
    "\n",
    "# preprocessed_features = preprocessing_pipeline.fit_transform(train_features)\n",
    "\n",
    "\n",
    "ML_model = Lasso(alpha=1)\n",
    "ML_model = Ridge(alpha=.1)\n",
    "# ML_model = LinearRegression()\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessing_pipeline),\n",
    "#     (\"scaler\", StandardScaler()), # No mejora la estimación escalando\n",
    "#     ('poly_features', PolynomialFeatures(degree=2)), # empeora con polynomal features\n",
    "    (\"estimator\", ML_model)\n",
    "])\n",
    "\n",
    "\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL IN ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONA PIPELINE LASSO WITH \n",
    "\n",
    "numerical = train.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical.remove('Id')\n",
    "numerical.remove('SalePrice')\n",
    "\n",
    "nominal = train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "          \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "          \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "ordinal = []\n",
    "\n",
    "\n",
    "X = train[nominal + ordinal + numerical] #LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# here we are going to instantiate a ColumnTransformer object with a list of tuples\n",
    "# each of which has a the name of the preprocessor\n",
    "# the transformation pipeline (could be a transformer)\n",
    "# and the list of column names we wish to transform\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "    (\"ordinal_preprocessor\", ordinal_pipeline, ordinal),\n",
    "    (\"numerical_preprocessor\", numerical_pipeline, numerical)\n",
    "])\n",
    "\n",
    "## If you want to test this pipeline run the following code\n",
    "\n",
    "# preprocessed_features = preprocessing_pipeline.fit_transform(train_features)\n",
    "\n",
    "\n",
    "ML_model = Lasso(alpha=190)\n",
    "ML_model = LinearRegression()\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessing_pipeline),\n",
    "#     (\"scaler\", StandardScaler()), # No mejora la estimación escalando\n",
    "#     ('poly_features', PolynomialFeatures(degree=2)),\n",
    "    (\"estimator\", LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = ct.fit_transform(X)\n",
    "aux = pd.df(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_features = preprocessing_pipeline.fit_transform(X_train)\n",
    "preprocessed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lasso=Lasso()\n",
    "parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100,200,300]}\n",
    "lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "\n",
    "lasso_regressor.fit(preprocessing_pipeline.fit_transform(X_train),y_train)\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando alpha de Lasso (alpha = 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'alpha':[100,150,170,180,190,200,220,250,300]}\n",
    "ML_model=Lasso()\n",
    "grid = GridSearchCV(ML_model,parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "grid.fit(preprocessing_pipeline.fit_transform(X_train),y_train)\n",
    "# Convert the results of CV into a dataframe\n",
    "results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score']]\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando alpha de Ridge (alpha = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100,200,300]}\n",
    "ML_model=Ridge()\n",
    "grid = GridSearchCV(ML_model,parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "grid.fit(preprocessing_pipeline.fit_transform(X_train),y_train)\n",
    "# Convert the results of CV into a dataframe\n",
    "results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score']]\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://salvatore-raieli.medium.com/a-complete-guide-to-linear-regression-using-gene-expression-data-regularization-f980ba6b11f7\n",
    "\n",
    "\n",
    "model = Lasso(alpha = 180)\n",
    "model.fit(preprocessing_pipeline.fit_transform(X_train), y_train)\n",
    "\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "coefs = model.coef_.flatten()\n",
    "names = X_train.columns\n",
    "genes = list(zip(names, coefs))\n",
    "feature =pd.DataFrame(genes, columns = [\"genes\", \"coefs\"])\n",
    "feature0 = feature.loc[(feature!=0).any(axis=1)]\n",
    "feature0 = feature[(feature != 0).all(1)]\n",
    "feature0.shape, feature.shape\n",
    "\n",
    "\n",
    "print(feature0.shape, feature.shape)\n",
    "\n",
    "coefs =feature0.sort_values(by=['coefs'])\n",
    "plt.figure(figsize=(20, 15))\n",
    "g = sns.barplot(x=\"genes\", y=\"coefs\", data=coefs, color= \"lightblue\")\n",
    "g.figsize=(16,10)\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONA LASSO\n",
    "\n",
    "X = train[['MSSubClass', 'LotArea', 'OverallQual']]\n",
    "y = train['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "model_lasso = Lasso(alpha=0.01)\n",
    "model_lasso.fit(X_train, y_train) \n",
    "y_pred= model_lasso.predict(X_test)\n",
    "\n",
    "\n",
    "print('Predictions with Polynomial Regression')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO PIPELINE FUNCIONA\n",
    "\n",
    "X = train[['MSSubClass','LotArea','OverallQual','LotFrontage']]#LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "imp_mean = SimpleImputer(missing_values =np.nan, strategy='mean')\n",
    "\n",
    "columns_imp_mean = ['LotFrontage']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "    (imp_mean,columns_imp_mean),\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "\n",
    "ML_model = Lasso(alpha=0.01)\n",
    "\n",
    "pipe = make_pipeline(column_trans, ML_model)\n",
    "\n",
    "print(cross_val_score(pipe,X_train,y_train,cv=5))\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred= pipe.predict(X_test)\n",
    "\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero hace la división de cross-validation y después hace el pipeline, \n",
    "# La diferencia de hacerlo así es que entonces cuando toma promedios para calcular como llenar los missing values, \n",
    "# estos promedios son con respecto al cross-validation\n",
    "cross_val_score(pipe,X,y,cv=5,scoring='accuracy').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONA PIPELINE LASSO WITH \n",
    "nominal = [\"MSZoning\", \"LotShape\", \"LandContour\", \"LotConfig\", \"Neighborhood\",\n",
    "           \"Condition1\", \"BldgType\", \"RoofStyle\",\n",
    "           \"Foundation\", \"CentralAir\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "          \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "          \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "numerical = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtUnfSF\",\n",
    "            \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"GrLivArea\", \"GarageArea\",\n",
    "            \"OpenPorchSF\"]\n",
    "\n",
    "X = train[nominal + ordinal + numerical] #LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# here we are going to instantiate a ColumnTransformer object with a list of tuples\n",
    "# each of which has a the name of the preprocessor\n",
    "# the transformation pipeline (could be a transformer)\n",
    "# and the list of column names we wish to transform\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "    (\"ordinal_preprocessor\", ordinal_pipeline, ordinal),\n",
    "    (\"numerical_preprocessor\", numerical_pipeline, numerical)\n",
    "])\n",
    "\n",
    "## If you want to test this pipeline run the following code\n",
    "\n",
    "# preprocessed_features = preprocessing_pipeline.fit_transform(train_features)\n",
    "\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessing_pipeline),\n",
    "    (\"scaler\", StandardScaler()), # No mejora la estimación escalando\n",
    "    (\"estimator\", LinearRegression())\n",
    "])\n",
    "\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONA PIPELINE LASSO WITH \n",
    "nominal = [\"MSZoning\", \"LotShape\", \"LandContour\", \"LotConfig\", \"Neighborhood\",\n",
    "           \"Condition1\", \"BldgType\", \"RoofStyle\",\n",
    "           \"Foundation\", \"CentralAir\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "          \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "          \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "numerical = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtUnfSF\",\n",
    "            \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"GrLivArea\", \"GarageArea\",\n",
    "            \"OpenPorchSF\"]\n",
    "\n",
    "X = train[nominal + ordinal + numerical] #LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# here we are going to instantiate a ColumnTransformer object with a list of tuples\n",
    "# each of which has a the name of the preprocessor\n",
    "# the transformation pipeline (could be a transformer)\n",
    "# and the list of column names we wish to transform\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "    (\"ordinal_preprocessor\", ordinal_pipeline, ordinal),\n",
    "    (\"numerical_preprocessor\", numerical_pipeline, numerical)\n",
    "])\n",
    "\n",
    "## If you want to test this pipeline run the following code\n",
    "\n",
    "# preprocessed_features = preprocessing_pipeline.fit_transform(train_features)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessing_pipeline),\n",
    "    (\"estimator\", LinearRegression())\n",
    "])\n",
    "\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A general rule of thumb: drop a dummy-encoded column if using a linear-based model, and do not drop it if using a tree-based model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value = y_test\n",
    "predicted_value = y_pred\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(true_value, predicted_value, c='crimson')\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "p1 = max(max(predicted_value), max(true_value))\n",
    "p2 = min(min(predicted_value), min(true_value))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is from [here](https://mahmoudyusof.github.io/general/scikit-learn-pipelines/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next cell is from https://mahmoudyusof.github.io/general/scikit-learn-pipelines/\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "## let's create a validation set from the training set\n",
    "\n",
    "msk = np.random.rand(len(train_df)) < 0.8\n",
    "\n",
    "val_df = train_df[~msk]\n",
    "\n",
    "train_df = train_df[msk]\n",
    "\n",
    "\n",
    "nominal = [\"MSZoning\", \"LotShape\", \"LandContour\", \"LotConfig\", \"Neighborhood\",\n",
    "           \"Condition1\", \"BldgType\", \"RoofStyle\",\n",
    "           \"Foundation\", \"CentralAir\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "          \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "          \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "numerical = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtUnfSF\",\n",
    "            \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"GrLivArea\", \"GarageArea\",\n",
    "            \"OpenPorchSF\"]\n",
    "\n",
    "train_features = train_df[nominal + ordinal + numerical]\n",
    "train_label = train_df[\"SalePrice\"]\n",
    "\n",
    "val_features = val_df[nominal + ordinal + numerical]\n",
    "val_label = val_df[\"SalePrice\"]\n",
    "\n",
    "test_features = test_df[nominal + ordinal + numerical]\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# here we are going to instantiate a ColumnTransformer object with a list of tuples\n",
    "# each of which has a the name of the preprocessor\n",
    "# the transformation pipeline (could be a transformer)\n",
    "# and the list of column names we wish to transform\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "    (\"ordinal_preprocessor\", ordinal_pipeline, ordinal),\n",
    "    (\"numerical_preprocessor\", numerical_pipeline, numerical)\n",
    "])\n",
    "\n",
    "## If you want to test this pipeline run the following code\n",
    "\n",
    "# preprocessed_features = preprocessing_pipeline.fit_transform(train_features)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessing_pipeline),\n",
    "    (\"estimator\", LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "complete_pipeline.fit(train_features, train_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# score = complete_pipeline.score(val_features, val_label)\n",
    "\n",
    "# print(score)\n",
    "\n",
    "# predictions = complete_pipeline.predict(test_features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = make_pipeline(column_trans, ML_model)\n",
    "\n",
    "# print(cross_val_score(complete_pipeline,X_train,y_train,cv=5))\n",
    "# pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO PIPELINE FUNCIONA\n",
    "\n",
    "X = train[['MSSubClass','LotArea','OverallQual','LotFrontage']]#LotFrontage y MasVnrType tiene NaNs\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "imp_mean = SimpleImputer(missing_values =np.nan, strategy='mean')\n",
    "\n",
    "columns_imp_mean = ['LotFrontage']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "    (imp_mean,columns_imp_mean),\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "\n",
    "ML_model = Lasso(alpha=0.01)\n",
    "\n",
    "pipe = make_pipeline(column_trans, ML_model)\n",
    "\n",
    "print(cross_val_score(pipe,X_train,y_train,cv=5))\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred= pipe.predict(X_test)\n",
    "\n",
    "\n",
    "print('ERRORS OF PREDICTIONS')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('r2_score', r2_score(y_test, y_pred)) \n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
